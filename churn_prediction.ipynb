{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CHURN PREDICTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import necessary libraries and methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:06.862185Z",
     "iopub.status.busy": "2021-11-07T17:28:06.861223Z",
     "iopub.status.idle": "2021-11-07T17:28:10.467074Z",
     "shell.execute_reply": "2021-11-07T17:28:10.466359Z",
     "shell.execute_reply.started": "2021-11-07T17:28:06.861592Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.stats import spearmanr\n",
    "import re\n",
    "\n",
    "PERIOD_DICT = {}\n",
    "PLAN_DICT = {}\n",
    "PACK_DICT = {}\n",
    "REGION_DICT = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dataset preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:10.469857Z",
     "iopub.status.busy": "2021-11-07T17:28:10.468855Z",
     "iopub.status.idle": "2021-11-07T17:28:21.800315Z",
     "shell.execute_reply": "2021-11-07T17:28:21.799198Z",
     "shell.execute_reply.started": "2021-11-07T17:28:10.469810Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Train.csv')\n",
    "zindi_data = pd.read_csv('Test.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can notice that **TOP_PACK** colunm may contain more information. So, feature engineering with this colum may improve dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:21.802876Z",
     "iopub.status.busy": "2021-11-07T17:28:21.802086Z",
     "iopub.status.idle": "2021-11-07T17:28:21.810880Z",
     "shell.execute_reply": "2021-11-07T17:28:21.810026Z",
     "shell.execute_reply.started": "2021-11-07T17:28:21.802810Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:21.812481Z",
     "iopub.status.busy": "2021-11-07T17:28:21.812253Z",
     "iopub.status.idle": "2021-11-07T17:28:21.824195Z",
     "shell.execute_reply": "2021-11-07T17:28:21.823310Z",
     "shell.execute_reply.started": "2021-11-07T17:28:21.812448Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cheсk missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:21.827284Z",
     "iopub.status.busy": "2021-11-07T17:28:21.827023Z",
     "iopub.status.idle": "2021-11-07T17:28:22.991766Z",
     "shell.execute_reply": "2021-11-07T17:28:22.990793Z",
     "shell.execute_reply.started": "2021-11-07T17:28:21.827250Z"
    }
   },
   "outputs": [],
   "source": [
    "def perc_missing(df):\n",
    "    '''prints out columns with missing values with its %'''\n",
    "    for col in df.columns:\n",
    "        pct = df[col].isna().mean() * 100\n",
    "        if (pct != 0):\n",
    "            print('{} => {}%'.format(col, round(pct, 2)))\n",
    "    \n",
    "perc_missing(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the calculations we can see that the percentage of empty values in the attributes **TIGO, ZONE1, ZONE2** is more than 50%. If we replace these values with the average, we will shift the data and it will be implausible. If we remove rows with empty values, we will lose a lot of information, so these attributes should be removed from the dataset. But, to be sure we can check performance of model including any combination of these features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next plot Nan values using heatmap for both train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:28:22.993561Z",
     "iopub.status.busy": "2021-11-07T17:28:22.993331Z",
     "iopub.status.idle": "2021-11-07T17:29:15.496435Z",
     "shell.execute_reply": "2021-11-07T17:29:15.495332Z",
     "shell.execute_reply.started": "2021-11-07T17:28:22.993533Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(data.isnull(), yticklabels=False, cmap='viridis', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:15.498718Z",
     "iopub.status.busy": "2021-11-07T17:29:15.498328Z",
     "iopub.status.idle": "2021-11-07T17:29:24.298761Z",
     "shell.execute_reply": "2021-11-07T17:29:24.297724Z",
     "shell.execute_reply.started": "2021-11-07T17:29:15.498671Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(zindi_data.isnull(), yticklabels=False, cmap='viridis', cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the balance of **CHURN** values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:24.300717Z",
     "iopub.status.busy": "2021-11-07T17:29:24.300487Z",
     "iopub.status.idle": "2021-11-07T17:29:24.535932Z",
     "shell.execute_reply": "2021-11-07T17:29:24.535257Z",
     "shell.execute_reply.started": "2021-11-07T17:29:24.300689Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data['CHURN'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "data['CHURN'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see on a plot, '0' values are much more frequent. \\\n",
    "To balance 0 and 1 values in CHURN we will drop all the rows, that have at least **k** Nan value with 0 in CHURN. But **thresh** parameter should be tuned experementally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:24.538715Z",
     "iopub.status.busy": "2021-11-07T17:29:24.537410Z",
     "iopub.status.idle": "2021-11-07T17:29:26.985672Z",
     "shell.execute_reply": "2021-11-07T17:29:26.984409Z",
     "shell.execute_reply.started": "2021-11-07T17:29:24.538662Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_zero = data.loc[data.CHURN == 0]\n",
    "# data_one = data.loc[data.CHURN == 1]\n",
    "# data_zero=data_zero.dropna(thresh = 11)\n",
    "# data = pd.concat([data_zero, data_one])\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:26.988048Z",
     "iopub.status.busy": "2021-11-07T17:29:26.987677Z",
     "iopub.status.idle": "2021-11-07T17:29:27.989113Z",
     "shell.execute_reply": "2021-11-07T17:29:27.987972Z",
     "shell.execute_reply.started": "2021-11-07T17:29:26.988001Z"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:27.991213Z",
     "iopub.status.busy": "2021-11-07T17:29:27.990896Z",
     "iopub.status.idle": "2021-11-07T17:29:31.017463Z",
     "shell.execute_reply": "2021-11-07T17:29:31.016326Z",
     "shell.execute_reply.started": "2021-11-07T17:29:27.991178Z"
    }
   },
   "outputs": [],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature engineering** \n",
    "We need to :\n",
    "1. convert values in categorical features into numeric\n",
    "2. replace all Nan values \n",
    "3. remove unnecessary features\n",
    "4. renerate new features if possible "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fistly, all the values in **user_id** field are different, and the **MRG** has only one value. This means that these features have absolutely no effect on the target value, so they should be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate features for categorical and numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:31.019776Z",
     "iopub.status.busy": "2021-11-07T17:29:31.018963Z",
     "iopub.status.idle": "2021-11-07T17:29:31.998336Z",
     "shell.execute_reply": "2021-11-07T17:29:31.997254Z",
     "shell.execute_reply.started": "2021-11-07T17:29:31.019738Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df = data.select_dtypes(include=['object'])\n",
    "num_df = data.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df.REGION.fillna('other', inplace=True)\n",
    "cat_df.REGION.replace(REGION_DICT, inplace=True)\n",
    "\n",
    "cat_df.TENURE.fillna('other', inplace=True)\n",
    "cat_df.TENURE.replace(TENURE_DICT, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['TENURE'] = cat_df['TENURE']\n",
    "df['REGULARITY'] = num_df['REGULARITY']\n",
    "df['CHURN'] = num_df['CHURN']\n",
    "df['DATA_VOLUME'] = num_df['DATA_VOLUME']\n",
    "print(df.shape[0])\n",
    "df = df.iloc[:df.shape[0]//2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=1)\n",
    "res = pd.DataFrame(imputer.fit_transform(df), columns=['TENURE', 'REGULARITY', 'CHURN', 'DATA_VOLUME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.000221Z",
     "iopub.status.busy": "2021-11-07T17:29:31.999930Z",
     "iopub.status.idle": "2021-11-07T17:29:32.015230Z",
     "shell.execute_reply": "2021-11-07T17:29:32.014108Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.000173Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.021827Z",
     "iopub.status.busy": "2021-11-07T17:29:32.021400Z",
     "iopub.status.idle": "2021-11-07T17:29:32.050319Z",
     "shell.execute_reply": "2021-11-07T17:29:32.049173Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.021794Z"
    }
   },
   "outputs": [],
   "source": [
    "num_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To deal with with missing values we will impute them. Dropping feature isn’t recommended because we can lose information. \\\n",
    "But we can use different imputer, such as **SimpleImputer**, **KNNImputer** or **DataWig** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the whole dataset we could extract three categorical featured : **REGION**, **TENURE** and **TOP_PACK**\n",
    "\n",
    "**REGION** column includes 14 unique region names and NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.066264Z",
     "iopub.status.busy": "2021-11-07T17:29:32.065623Z",
     "iopub.status.idle": "2021-11-07T17:29:32.281850Z",
     "shell.execute_reply": "2021-11-07T17:29:32.281142Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.066218Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df['REGION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create REGION_DICT that will be used for replacing all **REGION**s with int values. But to be sure that replacing will be implemented correctly, we need to check whether test dataset contain any additional **REGION** values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_regions = pd.concat([cat_df['REGION'], zindi_data['REGION']])\n",
    "all_regions = list(all_regions.unique())\n",
    "all_regions[1] = 'other'\n",
    "\n",
    "counter = 0\n",
    "for reg in all_regions:\n",
    "    REGION_DICT[reg] = counter\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next point - **TENURE** column. \\\n",
    "Seems like it may takes only 8 categories. That give us opportunity to convert it in numeric values manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.284134Z",
     "iopub.status.busy": "2021-11-07T17:29:32.283132Z",
     "iopub.status.idle": "2021-11-07T17:29:32.569325Z",
     "shell.execute_reply": "2021-11-07T17:29:32.568625Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.284093Z"
    }
   },
   "outputs": [],
   "source": [
    "cat_df['TENURE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENURE_DICT = {'D 3-6 month': 4.5, \n",
    "                'E 6-9 month': 7.5,\n",
    "                'F 9-12 month': 10.5,\n",
    "                'G 12-15 month': 13.5,\n",
    "                'H 15-18 month': 16.5,\n",
    "                'I 18-21 month': 19.5,\n",
    "                'J 21-24 month': 22.5,\n",
    "                'K > 24 month': 25\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As **TOP_PACK** contain pretty a lot of text information, we can extract some parts to creat new features for prediction model. Such as **PRICE**, **PERIOD** and **PLAN** \n",
    "\n",
    "Get all **TOP_PACK**s from train and test datasets to create separate dataframe, build new features and replace str values with SimpleEncoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract information from **TOP_PACK** we can use RegEx \\\n",
    "Create separate functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_expression_period(text):\n",
    "    text = str(text)\n",
    "    period_numeric = re.findall(r\"\\d{1,2}[d|h]\", text)\n",
    "    if len(period_numeric) > 0:\n",
    "        return period_numeric[-1]\n",
    "    period_char = re.findall(r\"(weekly|monthly|daily|oneday|30_days|night)\", text)\n",
    "    if len(period_char) > 0:\n",
    "        return period_char[-1]\n",
    "    return 'idk'\n",
    "\n",
    "\n",
    "def reg_expression_price(text):\n",
    "    text = str(text)\n",
    "    period_numeric = re.findall(r\"[0-9]+f\", text.replace(' ', ''))\n",
    "    if len(period_numeric) > 0:\n",
    "        return float(period_numeric[0][:-1])\n",
    "    else:\n",
    "        return -100\n",
    "    \n",
    "    \n",
    "def reg_expression_pack(text):\n",
    "    text = str(text)\n",
    "    plan = re.findall(r\"(mixt|onnet|data|pilot|cvm|allnet|wifi|internat|twter)\", text.replace('-','').replace(' ', ''))\n",
    "    if len(plan) > 0:\n",
    "        return plan[0]\n",
    "    else:\n",
    "        return 'idk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create *top_pack* dataframe and complete all manipulations with **TOP_PACK** column :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_packs = pd.concat([cat_df['TOP_PACK'], zindi_data['TOP_PACK']])\n",
    "all_packs = all_packs.unique()\n",
    "\n",
    "top_pack = pd.DataFrame()\n",
    "top_pack['TOP_PACK'] = pd.Series(all_packs).apply(str)\n",
    "top_pack['TOP_PACK'].append(pd.Series(['other']))\n",
    "top_pack['lower'] = top_pack['TOP_PACK'].str.lower()\n",
    "\n",
    "top_pack['TOP_PACK_int'] = top_pack['TOP_PACK']\n",
    "\n",
    "top_pack['PERIOD'] = top_pack['lower'].apply(reg_expression_period)\n",
    "top_pack['PRICE'] = top_pack['lower'].apply(reg_expression_price)\n",
    "top_pack['PLAN'] = top_pack['lower'].apply(reg_expression_pack)\n",
    "top_pack.drop('lower', axis=1, inplace=True)\n",
    "\n",
    "LE = LabelEncoder()\n",
    "top_pack['TOP_PACK_int'] = LE.fit_transform(top_pack['TOP_PACK_int'])\n",
    "top_pack['PERIOD'] = LE.fit_transform(top_pack['PERIOD'])\n",
    "top_pack['PLAN'] = LE.fit_transform(top_pack['PLAN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have separate dataframe with additional features. \\\n",
    "We can concat this dataframe with our train and test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can bring together all manipulation with datasets into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.805639Z",
     "iopub.status.busy": "2021-11-07T17:29:32.805118Z",
     "iopub.status.idle": "2021-11-07T17:29:32.831765Z",
     "shell.execute_reply": "2021-11-07T17:29:32.830842Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.805601Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_preparation(dataset):\n",
    "    global top_pack, REGION_DICT, TENURE_DICT\n",
    "    dataset.drop(['user_id', 'MRG'], inplace=True, axis=1)  \n",
    "        \n",
    "    #Separating our features into numerical and categorical\n",
    "    cat_df = dataset.select_dtypes(include=['object'])\n",
    "    num_df = dataset.select_dtypes(exclude=['object'])\n",
    "       \n",
    "    #Replace REGION and TENURE values\n",
    "    cat_df.REGION.fillna('other', inplace=True)\n",
    "    cat_df.REGION.replace(REGION_DICT, inplace=True)\n",
    "    \n",
    "    cat_df.TENURE.fillna('other', inplace=True)\n",
    "    cat_df.TENURE.replace(TENURE_DICT, inplace=True)\n",
    "\n",
    "    # Add PERIOD, PRICE, PLAN and replace  TOP_PACK values\n",
    "    cat_df['TOP_PACK'].fillna('other', inplace=True)\n",
    "    cat_df = pd.merge(cat_df, top_pack, how=\"left\", on='TOP_PACK')\n",
    "    cat_df.drop('TOP_PACK', axis=1, inplace=True)\n",
    "    cat_df.rename(columns={'TOP_PACK_int': 'TOP_PACK'}, inplace=True)\n",
    "\n",
    "    #Filling numeric columns with mean values\n",
    "\n",
    "    # num_df['DATA_VOLUME'] = df['DATA_VOLUME']\n",
    "\n",
    "    # imr = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    # num_columns = num_df.columns\n",
    "    # for i in num_columns:\n",
    "    #     num_df[[f'{i}']] = imr.fit_transform(num_df[[f'{i}']])\n",
    "    \n",
    "    #Ending columns convertation and cleaning we need to put together parts of dataset\n",
    "    dataset[num_df.columns] = num_df\n",
    "    dataset[cat_df.columns] = cat_df\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finnaly, we can clean up our dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:32.834227Z",
     "iopub.status.busy": "2021-11-07T17:29:32.833177Z",
     "iopub.status.idle": "2021-11-07T17:29:47.077656Z",
     "shell.execute_reply": "2021-11-07T17:29:47.076470Z",
     "shell.execute_reply.started": "2021-11-07T17:29:32.834191Z"
    }
   },
   "outputs": [],
   "source": [
    "data = data_preparation(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Test\n",
    "Spearman’s Rank Correlation. The function takes two real-valued samples as arguments and returns both the correlation coefficient in the range between -1 and 1 and the p-value for interpreting the significance of the coefficient. This statistical method quantifies the degree to which ranked variables are associated by a monotonic function, meaning an increasing or decreasing relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:47.119461Z",
     "iopub.status.busy": "2021-11-07T17:29:47.119079Z",
     "iopub.status.idle": "2021-11-07T17:29:54.039552Z",
     "shell.execute_reply": "2021-11-07T17:29:54.038396Z",
     "shell.execute_reply.started": "2021-11-07T17:29:47.119431Z"
    }
   },
   "outputs": [],
   "source": [
    "data1 = data['CHURN']\n",
    "for column in data.columns:\n",
    "    data2 = data[f'{column}']\n",
    "    stat, p = spearmanr(data1, data2)\n",
    "    if p > 0.05:\n",
    "        print(f'{column} and CHURN probably independent')\n",
    "    else:\n",
    "        print(f'{column} and CHURN probably dependent')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot final 0 and 1 value distribution in CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:54.041324Z",
     "iopub.status.busy": "2021-11-07T17:29:54.041078Z",
     "iopub.status.idle": "2021-11-07T17:29:54.269193Z",
     "shell.execute_reply": "2021-11-07T17:29:54.268442Z",
     "shell.execute_reply.started": "2021-11-07T17:29:54.041295Z"
    }
   },
   "outputs": [],
   "source": [
    "print(data['CHURN'].value_counts())\n",
    "plt.figure(figsize=(10,5))\n",
    "data['CHURN'].value_counts(normalize=True).plot(kind='bar')\n",
    "plt.ylabel('counts')\n",
    "plt.xlabel('Churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now dataset is ready for classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning part**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:54.306880Z",
     "iopub.status.busy": "2021-11-07T17:29:54.306647Z",
     "iopub.status.idle": "2021-11-07T17:29:55.116658Z",
     "shell.execute_reply": "2021-11-07T17:29:55.115527Z",
     "shell.execute_reply.started": "2021-11-07T17:29:54.306852Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import optuna  # pip install optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import lightgbm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset into three parts : train - 80%, test - 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:55.128136Z",
     "iopub.status.busy": "2021-11-07T17:29:55.127686Z",
     "iopub.status.idle": "2021-11-07T17:29:56.268726Z",
     "shell.execute_reply": "2021-11-07T17:29:56.267743Z",
     "shell.execute_reply.started": "2021-11-07T17:29:55.128103Z"
    }
   },
   "outputs": [],
   "source": [
    "y = data.loc[:, 'CHURN']\n",
    "x = data.drop('CHURN', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state=1)\n",
    "\n",
    "print(f'Train size - {X_train.shape[0]}')\n",
    "\n",
    "print(f'Test size - {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:29:56.270675Z",
     "iopub.status.busy": "2021-11-07T17:29:56.270324Z",
     "iopub.status.idle": "2021-11-07T17:33:04.403733Z",
     "shell.execute_reply": "2021-11-07T17:33:04.402652Z",
     "shell.execute_reply.started": "2021-11-07T17:29:56.270628Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial,X,y):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2,random_state=1)\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [1000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.2),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 1000, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 1000, step=50),\n",
    "        \"max_bin\": trial.suggest_int(\"max_bin\", 200, 300),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.2, 0.95, step=0.1),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "        \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        )\n",
    "    }\n",
    "    model = lightgbm.LGBMRegressor(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    rmse = mean_squared_error(test_y, preds,squared=False)\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "func = lambda trial: objective(trial, x, y)\n",
    "study.optimize(func, n_trials=20)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:04.405445Z",
     "iopub.status.busy": "2021-11-07T17:33:04.405169Z",
     "iopub.status.idle": "2021-11-07T17:33:04.414894Z",
     "shell.execute_reply": "2021-11-07T17:33:04.414225Z",
     "shell.execute_reply.started": "2021-11-07T17:33:04.405411Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params['n_estimators']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:04.416773Z",
     "iopub.status.busy": "2021-11-07T17:33:04.416363Z",
     "iopub.status.idle": "2021-11-07T17:33:04.434746Z",
     "shell.execute_reply": "2021-11-07T17:33:04.433266Z",
     "shell.execute_reply.started": "2021-11-07T17:33:04.416729Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = lightgbm.LGBMClassifier(n_estimators=best_params['n_estimators'], \n",
    "                              learning_rate=best_params['learning_rate'], \n",
    "                              num_leaves=best_params['num_leaves'], \n",
    "                              max_depth=best_params['max_depth'], \n",
    "                              min_data_in_leaf=best_params['min_data_in_leaf'], \n",
    "                              max_bin=best_params['max_bin'], \n",
    "                              lambda_l1=best_params['lambda_l1'], \n",
    "                              lambda_l2=best_params['lambda_l2'], \n",
    "                              min_gain_to_split=best_params['min_gain_to_split'], \n",
    "                              bagging_fraction=best_params['bagging_fraction'], \n",
    "                              bagging_freq=best_params['bagging_freq'], \n",
    "                              feature_fraction=best_params['feature_fraction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launch learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:04.437346Z",
     "iopub.status.busy": "2021-11-07T17:33:04.436036Z",
     "iopub.status.idle": "2021-11-07T17:33:14.842664Z",
     "shell.execute_reply": "2021-11-07T17:33:14.841780Z",
     "shell.execute_reply.started": "2021-11-07T17:33:04.437303Z"
    }
   },
   "outputs": [],
   "source": [
    "randmodel = clf.fit(X_train,y_train)\n",
    "randpred = randmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:14.845228Z",
     "iopub.status.busy": "2021-11-07T17:33:14.844412Z",
     "iopub.status.idle": "2021-11-07T17:33:14.877166Z",
     "shell.execute_reply": "2021-11-07T17:33:14.876216Z",
     "shell.execute_reply.started": "2021-11-07T17:33:14.845182Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy\")\n",
    "print(accuracy_score(y_test, randpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:14.878910Z",
     "iopub.status.busy": "2021-11-07T17:33:14.878667Z",
     "iopub.status.idle": "2021-11-07T17:33:14.990203Z",
     "shell.execute_reply": "2021-11-07T17:33:14.989258Z",
     "shell.execute_reply.started": "2021-11-07T17:33:14.878879Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Precision\")\n",
    "precision_score(y_test, randpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:14.992277Z",
     "iopub.status.busy": "2021-11-07T17:33:14.991766Z",
     "iopub.status.idle": "2021-11-07T17:33:15.101806Z",
     "shell.execute_reply": "2021-11-07T17:33:15.100658Z",
     "shell.execute_reply.started": "2021-11-07T17:33:14.992232Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Recall\")\n",
    "recall_score(y_test, randpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw confusion matrix in persantage ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:15.103348Z",
     "iopub.status.busy": "2021-11-07T17:33:15.103074Z",
     "iopub.status.idle": "2021-11-07T17:33:15.632261Z",
     "shell.execute_reply": "2021-11-07T17:33:15.630287Z",
     "shell.execute_reply.started": "2021-11-07T17:33:15.103318Z"
    }
   },
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, randpred)\n",
    "\n",
    "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
    "group_counts = ['{0:0.0f}'.format(value) for value in\n",
    "                conf.flatten()]\n",
    "group_percentages = ['{0:.2%}'.format(value) for value in\n",
    "                     conf.flatten()/np.sum(conf)]\n",
    "labels = [f'{v1}\\n{v2}\\n{v3}' for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(conf, annot=labels, fmt='', cmap='Greens')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot AUC ROC curve and calculate roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:15.634013Z",
     "iopub.status.busy": "2021-11-07T17:33:15.633788Z",
     "iopub.status.idle": "2021-11-07T17:33:16.386074Z",
     "shell.execute_reply": "2021-11-07T17:33:16.384911Z",
     "shell.execute_reply.started": "2021-11-07T17:33:15.633985Z"
    }
   },
   "outputs": [],
   "source": [
    "rp = randmodel.predict_proba(X_test)[:, 1]\n",
    "\n",
    "false_positive_rate1, true_positive_rate1, threshold1 = roc_curve(y_test, rp)\n",
    "\n",
    "print('roc_auc_score for lightGBM: ', roc_auc_score(y_test, rp))\n",
    "\n",
    "plt.subplots(1, figsize=(10,10))\n",
    "plt.title('Receiver Operating Characteristic - lightGBM')\n",
    "plt.plot(false_positive_rate1, true_positive_rate1)\n",
    "plt.plot([0, 1], ls=\"--\")\n",
    "plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T17:33:16.387968Z",
     "iopub.status.busy": "2021-11-07T17:33:16.387729Z",
     "iopub.status.idle": "2021-11-07T17:33:16.828749Z",
     "shell.execute_reply": "2021-11-07T17:33:16.827629Z",
     "shell.execute_reply.started": "2021-11-07T17:33:16.387932Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(clf.feature_importances_,X_train.columns)), columns=['Value','Feature'])\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For competition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission[\"user_id\"] = zindi_data[\"user_id\"]\n",
    "\n",
    "zindi_data = data_preparation(zindi_data)\n",
    "subpred = randmodel.predict_proba(zindi_data)\n",
    "submission[\"CHURN\"] = subpred[:, 1]\n",
    "submission.head()\n",
    "submission.to_csv('starter_code_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "679ca3d7e10d4fea823e60e28cb6f57bfb034a2481868839314afba603aaea83"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
